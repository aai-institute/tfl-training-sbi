{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext tfl_training_sbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-input-nbconv"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*\n",
       "This file is mainly copy-pasta from rise's examples\n",
       "https://github.com/damianavila/RISE/blob/master/examples/rise.css\n",
       "that was further customized for appliedAI purposes\n",
       "*/\n",
       "@import url('https://fonts.googleapis.com/css2?family=Work+Sans:wght@400&display=swap');\n",
       "\n",
       "\n",
       "body {\n",
       "    font-family: 'Work Sans', sans-serif !important;\n",
       "    text-transform: initial !important;\n",
       "    letter-spacing: initial !important;\n",
       "    font-weight: 400 !important;\n",
       "    line-height: 1.5 !important;\n",
       "    text-size-adjust: 100% !important;\n",
       "    ‑webkit‑text‑size‑adjust: 100% !important;\n",
       "}\n",
       "\n",
       "\n",
       ".reveal, div.text_cell_render, .md-slide, .sidebar-wrapper {\n",
       "    font-size: 1.5rem !important;\n",
       "}\n",
       "\n",
       ".navbar-default .navbar-nav > li > a {\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       ".filename {\n",
       "    font-size: 2.4rem !important;\n",
       "    color: #212529 !important;\n",
       "    font-weight: 600 !important;\n",
       "}\n",
       "\n",
       ".reveal, .md-slide {\n",
       "    color: white !important;\n",
       "}\n",
       "\n",
       "h1, h2 {\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       "h3, h4, h5, h6 {\n",
       "    color: #808080 !important;\n",
       "}\n",
       "\n",
       ".reveal p, .reveal ol, .reveal dl, .reveal ul,\n",
       "div.text_cell_render {\n",
       "    color: #212529 !important;\n",
       "}\n",
       "\n",
       "/*copied from stackoverflow, better spacing between list items*/\n",
       "li + li {\n",
       "  margin-top: 0.2em;\n",
       "}\n",
       "\n",
       "body.rise-enabled .reveal ol, body.rise-enabled .reveal dl, body.rise-enabled .reveal ul {\n",
       "    margin-left: 0.1em;\n",
       "    margin-top: 0.2em;\n",
       "}\n",
       "\n",
       ".reveal .rendered_html h1:first-child,\n",
       ".reveal .rendered_html h2:first-child,\n",
       ".reveal .rendered_html h3:first-child,\n",
       ".reveal .rendered_html h4:first-child,\n",
       ".reveal .rendered_html h5:first-child {\n",
       "    margin-top: 0.2em;\n",
       "}\n",
       "\n",
       ".CodeMirror-lines, .output_text {\n",
       "    font-size: 1.5rem !important;\n",
       "}\n",
       "\n",
       "\n",
       "h1.plan, h2.plan, h3.plan {\n",
       "    text-align: center;\n",
       "    padding-bottom: 30px;\n",
       "}\n",
       "\n",
       "ul.plan>li>span.plan-bold {\n",
       "    font-size: 110%;\n",
       "    padding: 4px;\n",
       "    font-weight: bold;\n",
       "    background-color: #eee;\n",
       "}\n",
       "\n",
       "ul.plan>li>ul.subplan>li>span.plan-bold {\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       ".plan-strike {\n",
       "    opacity: 0.4;\n",
       "/*    text-decoration: line-through; */\n",
       "}\n",
       "\n",
       "div.plan-container {\n",
       "    display: grid;\n",
       "    grid-template-columns: 50% 50%;\n",
       "}\n",
       "\n",
       "/*\n",
       " * this is to void xarray's html output to show the fallback textual representation\n",
       " * see also\n",
       "   * xarray.md and\n",
       "   * https://github.com/damianavila/RISE/issues/594\n",
       " */\n",
       ".reveal pre.xr-text-repr-fallback {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "#toc-header, .toc-item li {\n",
       "    margin: auto !important;\n",
       "    color: #808080 !important;\n",
       "}\n",
       "\n",
       "#toc, #toc-wrapper, .toc-item-num, #toc a, .toc {\n",
       "    margin: auto !important;\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       "#toc-wrapper {\n",
       "    top: auto !important;\n",
       "    bottom: auto !important;\n",
       "    margin-top: 2rem !important;\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       "\n",
       "#rise-header {\n",
       "    margin: 10px;\n",
       "    left: 5%;\n",
       "}\n",
       "\n",
       "#rise-footer {\n",
       "    margin: 10px;\n",
       "    right: 5%;\n",
       "}\n",
       "\n",
       "#rise-backimage {\n",
       "    opacity: 0.70;\n",
       "}\n",
       "\n",
       ".reveal img {\n",
       "    max-width: 100%;\n",
       "}\n",
       "\n",
       "\n",
       ".md-slide.title {\n",
       "  position: relative;\n",
       "  top: -50%;\n",
       "  margin-left: 5%;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input-nbconv",
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "$\\newcommand{\\vect}[1]{{\\mathbf{\\boldsymbol{#1}} }}$\n",
       "$\\newcommand{\\amax}{{\\text{argmax}}}$\n",
       "$\\newcommand{\\P}{{\\mathbb{P}}}$\n",
       "$\\newcommand{\\E}{{\\mathbb{E}}}$\n",
       "$\\newcommand{\\R}{{\\mathbb{R}}}$\n",
       "$\\newcommand{\\Z}{{\\mathbb{Z}}}$\n",
       "$\\newcommand{\\N}{{\\mathbb{N}}}$\n",
       "$\\newcommand{\\C}{{\\mathbb{C}}}$\n",
       "$\\newcommand{\\abs}[1]{{ \\left| #1 \\right| }}$\n",
       "$\\newcommand{\\simpl}[1]{{\\Delta^{#1} }}$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sbi.analysis\n",
    "import sbi.inference\n",
    "import sbi.utils\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from tfl_training_sbi.config import (\n",
    "    default_remote_storage,\n",
    "    get_config,\n",
    "    root_dir,\n",
    ")\n",
    "from tfl_training_sbi.data_utils import (\n",
    "    SIRSimulation,\n",
    "    SIRStdScaler,\n",
    "    load_sir_data,\n",
    ")\n",
    "from tfl_training_sbi.utils_sir import eval_sir_model\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "# ignore user warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# configure storage location\n",
    "storage = default_remote_storage()\n",
    "c = get_config(reload=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Likelihood and Ratio Estimation\n",
    "\n",
    " - Recap of Neural Posterior Estimation \n",
    " - Introduction to Neural Likelihood Estimation (NLE)\n",
    " - Exercise \n",
    " - Neural Ratio Estimation (NRE)\n",
    " - Pros & Cons of all three methods\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: the Goal of SBI\n",
    "\n",
    "- We want to learn the posterior $p(\\theta | \\mathbf{x})$ of a model $\\mathcal{M}$ given some data $\\mathbf{x}$\n",
    "- We do so using Bayes rule: \n",
    "    $$\n",
    "    p(\\theta | \\mathbf{x}) = \\frac{p(\\mathbf{x} | \\theta)\n",
    "    p(\\theta)}{p(\\mathbf{x})}\n",
    "    $$\n",
    "- However, the Likelihood is usually intractable\n",
    "- We overcome this challenge by sampling from the joint distribution\n",
    "  $p(\\mathbf{x}, \\theta)=p(\\mathbf{x}\\mid \\theta)p(\\theta)$ and learn a conditional density estimator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Neural Posterior Estimation\n",
    "\n",
    "- Direct mapping from observations $\\mathbf{x}$ to posterior $p(\\theta|\\mathbf{x})$\n",
    "- E.g. learning Gaussian mixture, parameterized by neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Likelihood Function\n",
    "\n",
    "- The Likelihood function is the probability of the data given the model parameters, i.e. $p(\\mathbf{x}|\\theta)$\n",
    "- This is a density function in $\\mathbf{x}$ for fixed $\\theta$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning the Likelihood Function with a Neural Network\n",
    "\n",
    "- NLE learns $p(\\mathbf{x}|\\theta)$ instead of $p(\\theta|\\mathbf{x})$\n",
    "- Both are conditional density estimation problems ([NB 02](nb_02_conditional_density_estimation.ipynb))\n",
    "- NLE is a Maximum Likelihood Estimation problem on $\\{(\\theta, \\mathbf{x})_i\n",
    "  \\}^N_{i=1}$ where $\\mathcal{M}(\\theta_i) = \\mathbf{x}_i$\n",
    "- $\\hat{p}(\\theta \\mid \\mathbf{x}) = p(\\theta\\mid\\mathbf{x})p(\\theta)$ is a scaled version with constant $frac{1}{p(\\mathbf{x})}$ \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling from the NLE Posterior \n",
    "\n",
    "MCMC -> bayes training \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why should I use NLE\n",
    "\n",
    "The goal is to obtain the posterior $p(\\theta \\mid \\mathbf{x})$, why learn\n",
    "$p(\\mathbf{x} \\mid \\theta)$?\n",
    "\n",
    " - Reduced complexity due to factorization for i.i.d. observations \n",
    " - Amortized when increasing the hierarchy \n",
    " - Advantage when $\\operatorname{dim}(\\theta) \\gg \\operatorname{dim}(\\mathbf{x})$\n",
    " - Only the Likelihood is intractable \n",
    " - No correction for sequential learning "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick Intro to the `sbi` Toolkit\n",
    "\n",
    "- Open Source Software for Simulation-Based Inference; <i class=\"fa-brands fa-github\"></i>[GitHub](https://www.mackelab.org/sbi/)\n",
    "- Provides SNPE, SNLE and SNRE as well as analysis tools out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# define a uninformative prior\n",
    "prior = sbi.utils.BoxUniform(\n",
    "    low=torch.tensor([0.0, 0.0]), high=torch.tensor([1.0, 1.0]) * 2\n",
    ")\n",
    "\n",
    "\n",
    "# define a simple simulator\n",
    "def example_simulator(theta: torch.tensor):\n",
    "    return torch.sin(theta) + torch.randn_like(theta) * 0.1\n",
    "\n",
    "\n",
    "# obtain samples from joint distribution\n",
    "thetas = prior.sample((1_000,))\n",
    "x = example_simulator(thetas)\n",
    "\n",
    "\n",
    "# use the first sample as observation\n",
    "thetas, theta_obs = thetas[1:, :], thetas[0, :]\n",
    "x, x_obs = x[1:, :], x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 142 epochs."
     ]
    }
   ],
   "source": [
    "# obtain a posterior approx. via NPE\n",
    "inference = sbi.inference.SNPE(prior=prior, density_estimator=\"maf\")\n",
    "density_estimator = inference.append_simulations(thetas, x).train()\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d47a3497a54142aad8420808d4fa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = posterior.sample((10_000,), x=x_obs)\n",
    "_ = sbi.analysis.pairplot(\n",
    "    samples=samples,\n",
    "    points=theta_obs,\n",
    "    points_colors=\"r\",\n",
    "    upper=\"kde\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Application of NLE on the SIR Dataset\n",
    "\n",
    "We will use the same data as in the previous notebook, but now we will use the\n",
    "neural likelihood estimator to construct the posterior.\n",
    "\n",
    "**Task:** Use the provided the pseudo simulator to obtain the SIR dataset. Also,\n",
    "standardized the data and split it into a training and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-simulated data from disk\n",
    "data_theta, data_x = load_sir_data(c.data)\n",
    "\n",
    "# initialize the scaler and the dataset\n",
    "sir_scaler = SIRStdScaler()\n",
    "dataset_z = sir_scaler({\"theta\": torch.tensor(data_theta[:-1]), \"obs\": torch.tensor(data_x[:-1])})\n",
    "theta_z, x_z = dataset_z[\"theta\"], dataset_z[\"obs\"]\n",
    "\n",
    "# remove the last pair from the dataset\n",
    "obs_theta, obs_x = torch.tensor(data_theta[-1]).unsqueeze(0), torch.tensor(\n",
    "    data_x[-1]\n",
    ").unsqueeze(0)\n",
    "\n",
    "data = sir_scaler({\"theta\": obs_theta, \"obs\": obs_x})\n",
    "obs_theta_z, obs_x_z = data[\"theta\"], data[\"obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = torch.distributions.LogNormal(\n",
    "    loc=torch.tensor([math.log(0.4), math.log(0.125)]),\n",
    "    scale=torch.tensor([0.5, 0.2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 119"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# obtain a posterior approx. via NPE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m inference \u001b[39m=\u001b[39m sbi\u001b[39m.\u001b[39minference\u001b[39m.\u001b[39mSNLE(prior\u001b[39m=\u001b[39mprior)\n\u001b[0;32m----> 3\u001b[0m density_estimator \u001b[39m=\u001b[39m inference\u001b[39m.\u001b[39;49mappend_simulations(theta_z, x_z)\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      4\u001b[0m posterior \u001b[39m=\u001b[39m inference\u001b[39m.\u001b[39mbuild_posterior(density_estimator)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/sbi/inference/snle/snle_base.py:229\u001b[0m, in \u001b[0;36mLikelihoodEstimator.train\u001b[0;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, resume_training, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m theta_batch, x_batch \u001b[39m=\u001b[39m (\n\u001b[1;32m    225\u001b[0m     batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device),\n\u001b[1;32m    226\u001b[0m     batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device),\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[39m# Evaluate on x with theta as context.\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m train_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss(theta\u001b[39m=\u001b[39;49mtheta_batch, x\u001b[39m=\u001b[39;49mx_batch)\n\u001b[1;32m    230\u001b[0m train_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(train_losses)\n\u001b[1;32m    231\u001b[0m train_log_probs_sum \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m train_losses\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/sbi/inference/snle/snle_base.py:396\u001b[0m, in \u001b[0;36mLikelihoodEstimator._loss\u001b[0;34m(self, theta, x)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_loss\u001b[39m(\u001b[39mself\u001b[39m, theta: Tensor, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    391\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Return loss for SNLE, which is the likelihood of $-\\log q(x_i | \\theta_i)$.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39m        Negative log prob.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_neural_net\u001b[39m.\u001b[39;49mlog_prob(x, context\u001b[39m=\u001b[39;49mtheta)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/distributions/base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m context\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of input items must be equal to number of context items.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_prob(inputs, context)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/flows/base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, inputs, context):\n\u001b[1;32m     38\u001b[0m     embedded_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 39\u001b[0m     noise, logabsdet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(inputs, context\u001b[39m=\u001b[39;49membedded_context)\n\u001b[1;32m     40\u001b[0m     log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution\u001b[39m.\u001b[39mlog_prob(noise, context\u001b[39m=\u001b[39membedded_context)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m log_prob \u001b[39m+\u001b[39m logabsdet\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/transforms/base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     funcs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transforms\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cascade(inputs, funcs, context)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[39m=\u001b[39m func(outputs, context)\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/transforms/autoregressive.py:38\u001b[0m, in \u001b[0;36mAutoregressiveTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 38\u001b[0m     autoregressive_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautoregressive_net(inputs, context)\n\u001b[1;32m     39\u001b[0m     outputs, logabsdet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elementwise_forward(inputs, autoregressive_params)\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/transforms/made.py:281\u001b[0m, in \u001b[0;36mMADE.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m    279\u001b[0m     temps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(temps)\n\u001b[1;32m    280\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m--> 281\u001b[0m     temps \u001b[39m=\u001b[39m block(temps, context)\n\u001b[1;32m    282\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer(temps)\n\u001b[1;32m    283\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/transforms/made.py:120\u001b[0m, in \u001b[0;36mMaskedFeedforwardBlock.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     temps \u001b[39m=\u001b[39m inputs\n\u001b[0;32m--> 120\u001b[0m temps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(temps)\n\u001b[1;32m    121\u001b[0m temps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(temps)\n\u001b[1;32m    122\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(temps)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/nflows/transforms/made.py:72\u001b[0m, in \u001b[0;36mMaskedLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/tfl-training-sbi-JNOLu5ZV-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1254\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m-> 1254\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m_parameters\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m   1255\u001b[0m         \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m _parameters:\n\u001b[1;32m   1256\u001b[0m             \u001b[39mreturn\u001b[39;00m _parameters[name]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# obtain a posterior approx. via NPE\n",
    "# todo: the prior is not correct as labels have been scaled \n",
    "inference = sbi.inference.SNLE(prior=prior)\n",
    "density_estimator = inference.append_simulations(theta_z, x_z).train()\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Ratio Estimation \n",
    "\n",
    "one slide; all the info\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Considerations for NPE vs. NLE and NRE\n",
    "\n",
    "What do we have to keep in mind; when do we prefer which approach\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "summarize pros and cons for each method\n",
    "\n",
    "| Method | Pros | Cons |\n",
    "|:---|:---|:---|\n",
    "|NPE |... |... |\n",
    "|NLE |... |... |\n",
    "|NRE |... |... |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- sbi: A toolkit for simulation-based inference; [GitHub](https://www.mackelab.org/sbi/credits/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "remove-cell-nbconv"
    ]
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Thank you for the attention!</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
