{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext tfl_training_sbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-input-nbconv"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*\n",
       "This file is mainly copy-pasta from rise's examples\n",
       "https://github.com/damianavila/RISE/blob/master/examples/rise.css\n",
       "that was further customized for appliedAI purposes\n",
       "*/\n",
       "@import url('https://fonts.googleapis.com/css2?family=Work+Sans:wght@400&display=swap');\n",
       "\n",
       "\n",
       "body {\n",
       "    font-family: 'Work Sans', sans-serif !important;\n",
       "    text-transform: initial !important;\n",
       "    letter-spacing: initial !important;\n",
       "    font-weight: 400 !important;\n",
       "    line-height: 1.5 !important;\n",
       "    text-size-adjust: 100% !important;\n",
       "    ‑webkit‑text‑size‑adjust: 100% !important;\n",
       "}\n",
       "\n",
       "\n",
       ".reveal, div.text_cell_render, .md-slide, .sidebar-wrapper {\n",
       "    font-size: 1.5rem !important;\n",
       "}\n",
       "\n",
       ".navbar-default .navbar-nav > li > a {\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       ".filename {\n",
       "    font-size: 2.4rem !important;\n",
       "    color: #212529 !important;\n",
       "    font-weight: 600 !important;\n",
       "}\n",
       "\n",
       ".reveal, .md-slide {\n",
       "    color: white !important;\n",
       "}\n",
       "\n",
       "h1, h2 {\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       "h3, h4, h5, h6 {\n",
       "    color: #808080 !important;\n",
       "}\n",
       "\n",
       ".reveal p, .reveal ol, .reveal dl, .reveal ul,\n",
       "div.text_cell_render {\n",
       "    color: #212529 !important;\n",
       "}\n",
       "\n",
       "/*copied from stackoverflow, better spacing between list items*/\n",
       "li + li {\n",
       "  margin-top: 0.2em;\n",
       "}\n",
       "\n",
       "body.rise-enabled .reveal ol, body.rise-enabled .reveal dl, body.rise-enabled .reveal ul {\n",
       "    margin-left: 0.1em;\n",
       "    margin-top: 0.2em;\n",
       "}\n",
       "\n",
       ".reveal .rendered_html h1:first-child,\n",
       ".reveal .rendered_html h2:first-child,\n",
       ".reveal .rendered_html h3:first-child,\n",
       ".reveal .rendered_html h4:first-child,\n",
       ".reveal .rendered_html h5:first-child {\n",
       "    margin-top: 0.2em;\n",
       "}\n",
       "\n",
       ".CodeMirror-lines, .output_text {\n",
       "    font-size: 1.5rem !important;\n",
       "}\n",
       "\n",
       "\n",
       "h1.plan, h2.plan, h3.plan {\n",
       "    text-align: center;\n",
       "    padding-bottom: 30px;\n",
       "}\n",
       "\n",
       "ul.plan>li>span.plan-bold {\n",
       "    font-size: 110%;\n",
       "    padding: 4px;\n",
       "    font-weight: bold;\n",
       "    background-color: #eee;\n",
       "}\n",
       "\n",
       "ul.plan>li>ul.subplan>li>span.plan-bold {\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       ".plan-strike {\n",
       "    opacity: 0.4;\n",
       "/*    text-decoration: line-through; */\n",
       "}\n",
       "\n",
       "div.plan-container {\n",
       "    display: grid;\n",
       "    grid-template-columns: 50% 50%;\n",
       "}\n",
       "\n",
       "/*\n",
       " * this is to void xarray's html output to show the fallback textual representation\n",
       " * see also\n",
       "   * xarray.md and\n",
       "   * https://github.com/damianavila/RISE/issues/594\n",
       " */\n",
       ".reveal pre.xr-text-repr-fallback {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "#toc-header, .toc-item li {\n",
       "    margin: auto !important;\n",
       "    color: #808080 !important;\n",
       "}\n",
       "\n",
       "#toc, #toc-wrapper, .toc-item-num, #toc a, .toc {\n",
       "    margin: auto !important;\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       "#toc-wrapper {\n",
       "    top: auto !important;\n",
       "    bottom: auto !important;\n",
       "    margin-top: 2rem !important;\n",
       "    color: #00747b !important;\n",
       "}\n",
       "\n",
       "\n",
       "#rise-header {\n",
       "    margin: 10px;\n",
       "    left: 5%;\n",
       "}\n",
       "\n",
       "#rise-footer {\n",
       "    margin: 10px;\n",
       "    right: 5%;\n",
       "}\n",
       "\n",
       "#rise-backimage {\n",
       "    opacity: 0.70;\n",
       "}\n",
       "\n",
       ".reveal img {\n",
       "    max-width: 100%;\n",
       "}\n",
       "\n",
       "\n",
       ".md-slide.title {\n",
       "  position: relative;\n",
       "  top: -50%;\n",
       "  margin-left: 5%;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input-nbconv",
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "$\\newcommand{\\vect}[1]{{\\mathbf{\\boldsymbol{#1}} }}$\n",
       "$\\newcommand{\\amax}{{\\text{argmax}}}$\n",
       "$\\newcommand{\\P}{{\\mathbb{P}}}$\n",
       "$\\newcommand{\\E}{{\\mathbb{E}}}$\n",
       "$\\newcommand{\\R}{{\\mathbb{R}}}$\n",
       "$\\newcommand{\\Z}{{\\mathbb{Z}}}$\n",
       "$\\newcommand{\\N}{{\\mathbb{N}}}$\n",
       "$\\newcommand{\\C}{{\\mathbb{C}}}$\n",
       "$\\newcommand{\\abs}[1]{{ \\left| #1 \\right| }}$\n",
       "$\\newcommand{\\simpl}[1]{{\\Delta^{#1} }}$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.png\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">\n",
    "    <h1>Evaluating Simulation-Based Inference</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, log, ones, zeros\n",
    "from typing import Callable\n",
    "\n",
    "from sbi.analysis import run_sbc, sbc_rank_plot\n",
    "from sbi.inference import SNPE\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.analysis import pairplot\n",
    "\n",
    "from tfl_training_sbi.config import (\n",
    "    default_remote_storage,\n",
    "    get_config,\n",
    "    root_dir,\n",
    ")\n",
    "from tfl_training_sbi.data_utils import (\n",
    "    SIRSimulation,\n",
    "    load_sir_data,\n",
    ")\n",
    "\n",
    "storage = default_remote_storage()\n",
    "c = get_config(reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How can we evaluate the performance of SBI?\n",
    "\n",
    "\n",
    "- Neural density estimators are accurate only in the limit of infinite training data\n",
    "- The posteriors we get are only approximations\n",
    "- How do we know SBI is reliable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methods to evaluate the performance of SBI\n",
    "\n",
    "\n",
    "1) Checking neural network training convergence\n",
    "    - Monitor posterior log-probability of test data pairs $(\\theta, x)$ \n",
    "2) Posterior predictive checks\n",
    "    - Test whether the inferred parameters $\\theta \\sim q(\\theta | x_o)$ reproduce the observed data $x_o$\n",
    "3) Calibration checks\n",
    "    - Check whether the uncertainties of the inferred posteriors are well-calibrated \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1) Neural network training convergence\n",
    "\n",
    "- Use logging tools like `lightning`, `tensorboard` or `wandb` (weights and biases, wandb.ai) to track training convergence via the validation loss. \n",
    "- Validation loss: use unseen data simulated from the prior to evaluate the conditional density estimator: \n",
    "\n",
    "```python\n",
    "validation_loss = -net.log_prob(theta, x)  # - log p(theta | x)\n",
    "```\n",
    "\n",
    "- Stop training when `validation_loss` converges (e.g., no decrease for 20 epochs)\n",
    "```python\n",
    "trainer = SNPE().append_simulations(theta, x)\n",
    "net = trainer.train(validation_fractior=0.2, stop_after_epochs=20)\n",
    "\n",
    "```\n",
    "- Use `validation_loss` to perform neural architecture search (e.g., for embedding nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def simulator(theta: Tensor, simulator_scale: float = 0.1) -> Tensor:\n",
    "    return torch.ones_like(theta) + theta + simulator_scale * torch.randn_like(theta)\n",
    "\n",
    "# choose prior\n",
    "num_dims = 3\n",
    "prior = BoxUniform(-ones(num_dims), ones(num_dims))\n",
    "\n",
    "# run simulations\n",
    "num_simulations = 2000\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulator(theta)\n",
    "\n",
    "# train\n",
    "trainer = SNPE(prior).append_simulations(theta, x)\n",
    "trainer.train()\n",
    "posterior = trainer.build_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1) Check training convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(trainer.summary[\"training_log_probs\"])\n",
    "plt.plot(trainer.summary[\"validation_log_probs\"])\n",
    "plt.xlabel(\"epochs\", fontsize=fontsize)\n",
    "plt.ylabel(\"posterior - $\\log p(\\\\theta \\mid x)$\", fontsize=fontsize)\n",
    "plt.legend([\"training\", \"validation\"], fontsize=fontsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualizing the posterior\n",
    "\n",
    "Parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "theta_o = zeros(num_dims)\n",
    "x_o = simulator(theta_o)\n",
    "num_samples = 1000\n",
    "posterior_samples = posterior.sample((num_samples,), x=x_o)\n",
    "\n",
    "pairplot([theta, posterior_samples], points=theta_o, \n",
    "         labels=[f\"theta {i}\" for i in range(num_dims)], samples_labels=[\"prior\", \"posterior\"], \n",
    "         points_labels=[\"true theta\"], legend=True, hist_diag=dict(bins=\"auto\", density=True), figsize=(8, 8),\n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2) Posterior predictive checks\n",
    "\n",
    "- The posterior characterizes those model parameters that are likely to have generate the observed data $x_o$\n",
    "- Thus, simulating data with inferred parameters should reproduce $x_o$ ($\\pm$ simulator noise)\n",
    "- Posterior predictive checks: \n",
    "    - Simulate data with parameters sampled from the posterior\n",
    "    - Visually or quantitatively compare to $x_o$\n",
    "    - If they do not match, something is off! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "posterior_predictive_samples = simulator(posterior_samples)\n",
    "pairplot([x, posterior_predictive_samples], points=x_o, labels=[f\"x_{i}\" for i in range(num_dims)], legend=True,\n",
    "         samples_labels=[\"prior\\npredictive\", \"posterior\\npredictive\"], points_labels=[\"observed data\"], \n",
    "         hist_diag=dict(bins=\"auto\", density=True),\n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3) Posterior calibration checks\n",
    "\n",
    "- Check whether the SBI posterior uncertainties are well-calibrated: whether the posterior is over- or underconfident (on average)\n",
    "- Indirect check: we do not need access to the true posterior\n",
    "- Requirements \n",
    "    - Access to a set of unseen test data $(\\theta, x)$ (~100s)\n",
    "    - Fast inference for each test data point (computationally feasible only for amortized SBI methods)\n",
    "    - Fast posterior sampling (computationally demanding for NLE / NRE). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simulation-Based Calibration (SBC)\n",
    "\n",
    "### Rough idea\n",
    "\n",
    "- Repeat inference many times with different test data pairs $(\\theta_i, x_i)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\theta^* &\\sim p(\\theta)\\\\\n",
    "    x^* &\\sim p(x | \\theta^*)\\\\\n",
    "    \\{\\theta_1, \\ldots \\theta_L\\} &\\sim p_i(\\theta | x^*)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Calculate the rank of $\\theta_i$ under corresponding posterior $p_i(\\theta | x_i)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    r_i = \\sum_{j=1}^L \\mathbb{I}[f(\\theta_j) < f(\\theta_i^*)] \\in [0, L], \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Check whether distribution of ranks is uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simulation-Based Calibration (SBC)\n",
    "\n",
    "### Intuition\n",
    "\n",
    "- There is uncertainty in the simulator (aleatoric) and in the data (epistemic)\n",
    "- Posterior is **not centered on true parameter** $\\theta_o$\n",
    "- But $\\theta_o$ should be somewhere within the posterior (randomly)\n",
    "- On average, it should be everywhere within posterior mass (uniform ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pairplot([theta, posterior_samples], points=theta_o, labels=[f\"theta {i}\" for i in range(num_dims)],\n",
    "         samples_labels=[\"prior\", \"posterior\"], points_labels=[\"true theta\"],\n",
    "         legend=True, hist_diag=dict(bins=\"auto\", density=True),\n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simulation-Based Calibration\n",
    "\n",
    "### Interpretation\n",
    "<img src=\"_static/images/fig2.4_sbc_illustration.png\" alt=\"Snow\" style=\"width:100%;\">\n",
    "\n",
    "- The posterior is **well-calibrated** only if the ranks are distributed uniformly (necessary condition)\n",
    "- Shape of rank-distribution gives insight about **mis-calibration**\n",
    "- Can be gamed by setting posterior=prior (it's not a sufficient condition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: applying SBC to Gaussian simulator from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# generate test data set from prior\n",
    "num_sbc_simulations = 1000\n",
    "num_posterior_samples = 1000\n",
    "theta_test = prior.sample((num_sbc_simulations,))\n",
    "x_test = simulator(theta_test, simulator_scale=0.1)\n",
    "\n",
    "# run SBC\n",
    "ranks, dap_samples = run_sbc(theta_test, x_test, posterior, num_posterior_samples=num_posterior_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plot the ranks as an empirical CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = sbc_rank_plot(ranks, num_posterior_samples, \n",
    "                        parameter_labels=[f\"theta {i}\" for i in range(num_dims)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: detecting mis-calibration using SBC\n",
    "\n",
    "Note: the posterior estimator was trained on data with `simulator_scale=0.1`\n",
    "\n",
    "1) Task 1: generate slightly **misspecified** test data by using `simulator_scale=0.05`\n",
    "2) Task 2: run SBC using that test data and plot the distribution of ranks.\n",
    "3) Task 3: interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: \n",
    "# generate test theta from the prior\n",
    "# theta_test = ...\n",
    "# generate test data from a misspecified simulator\n",
    "# x_test = ...\n",
    "\n",
    "# run SBC as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Solution task 1.\n",
    "# %load -r 6-13 solutions/solutions_nb_05.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretation\n",
    "\n",
    "- Compare the shape to the middle column in the example Figure above. \n",
    "- Because the test data comes from a distribution with smaller variance, our density estimator systematically predicts posteriors with too much variance (dark red in Figure above) -- it is *overdispersed* or underconfident. \n",
    "- Optional: Try using test data with higher variance and you will see the opposite pattern -- *underdispersion*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "### Reason for SBI evaluation\n",
    "\n",
    "- Training data is limited\n",
    "- SBI posteriors are approximate, \n",
    "- No access to ground-truth posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Methods for SBI evaluation\n",
    "\n",
    "1) Checking training convergence of neural-networks via validation-loss (optimize architectures)\n",
    "2) Posterior predictive checks: test whether data simulator from the posterior matches observation (sufficient)\n",
    "3) Calibration checks: test whether posterior-uncertainties are well-calibrated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "1) Why do we need to evaluate SBI methods? \n",
    "2) What are the current three essential steps of validation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Acknowledgments\n",
    "\n",
    "- SBI package for code and figures.\n",
    "- Talts et al. 2018 for their paper on [simulation-based calibration](https://arxiv.org/abs/1804.06788).\n",
    "- SBC intuition figure taken from [Jan Boelts' PhD thesis](https://publikationen.uni-tuebingen.de/xmlui/handle/10900/143554)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.png\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">\n",
    "    <h2>Thank you for your attention!</h2>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
